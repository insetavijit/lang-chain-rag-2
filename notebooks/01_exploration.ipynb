{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RAG Document Q&A - Exploration Notebook\n",
                "\n",
                "This notebook is for testing API connections and experimenting with the RAG system components."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup & Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load environment variables\n",
                "from dotenv import load_dotenv\n",
                "import os\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "print(\"Environment Check:\")\n",
                "print(f\"  OpenRouter API Key: {'✓ Set' if os.getenv('OPENROUTER_API_KEY') else '✗ Missing'}\")\n",
                "print(f\"  Groq API Key: {'✓ Set' if os.getenv('GROQ_API_KEY') else '✗ Missing'}\")\n",
                "print(f\"  Langfuse Keys: {'✓ Set' if os.getenv('LANGFUSE_SECRET_KEY') else '✗ Missing'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test configuration loading\n",
                "from src.config import settings\n",
                "\n",
                "print(\"Configuration:\")\n",
                "print(f\"  Active Provider: {settings.get_active_llm_provider()}\")\n",
                "print(f\"  LLM Model: {settings.llm_model}\")\n",
                "print(f\"  Embedding Model: {settings.embedding_model}\")\n",
                "print(f\"  Chunk Size: {settings.chunk_size}\")\n",
                "print(f\"  Chunk Overlap: {settings.chunk_overlap}\")\n",
                "print(f\"  Retrieval K: {settings.retrieval_k}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Test LLM Connection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.chain import get_llm\n",
                "\n",
                "# Create LLM instance\n",
                "llm = get_llm()\n",
                "\n",
                "# Test with a simple message\n",
                "response = llm.invoke(\"Hello! Say 'RAG system ready!' if you can hear me.\")\n",
                "print(f\"LLM Response: {response.content}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test streaming\n",
                "print(\"Streaming test:\")\n",
                "for chunk in llm.stream(\"Count from 1 to 5, one number per line.\"):\n",
                "    print(chunk.content, end=\"\", flush=True)\n",
                "print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Test Embeddings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.embeddings import get_embeddings, embed_query\n",
                "\n",
                "# Get embeddings model\n",
                "embeddings = get_embeddings()\n",
                "print(f\"Embeddings Model: {embeddings.model}\")\n",
                "\n",
                "# Test embedding a query\n",
                "test_text = \"What is RAG and how does it work?\"\n",
                "embedding = embed_query(test_text)\n",
                "print(f\"\\nEmbedding dimension: {len(embedding)}\")\n",
                "print(f\"First 5 values: {embedding[:5]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Test Document Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.loaders import load_document\n",
                "from src.chunker import chunk_documents\n",
                "\n",
                "# Create a test document\n",
                "test_content = \"\"\"# RAG System Overview\n",
                "\n",
                "Retrieval-Augmented Generation (RAG) is a technique that enhances LLM responses\n",
                "by retrieving relevant information from a knowledge base.\n",
                "\n",
                "## How It Works\n",
                "\n",
                "1. Documents are loaded and split into chunks\n",
                "2. Chunks are converted to vector embeddings\n",
                "3. Embeddings are stored in a vector database\n",
                "4. User queries are converted to embeddings\n",
                "5. Similar chunks are retrieved\n",
                "6. LLM generates response using retrieved context\n",
                "\n",
                "## Benefits\n",
                "\n",
                "- Grounded responses based on actual documents\n",
                "- Reduced hallucination\n",
                "- Up-to-date information\n",
                "- Source citations\n",
                "\"\"\"\n",
                "\n",
                "# Save test file\n",
                "test_path = \"data/documents/test_doc.txt\"\n",
                "os.makedirs(\"data/documents\", exist_ok=True)\n",
                "with open(test_path, \"w\") as f:\n",
                "    f.write(test_content)\n",
                "\n",
                "# Load and chunk\n",
                "docs = load_document(test_path)\n",
                "print(f\"Loaded {len(docs)} document(s)\")\n",
                "\n",
                "chunks = chunk_documents(docs)\n",
                "print(f\"Created {len(chunks)} chunk(s)\")\n",
                "\n",
                "for i, chunk in enumerate(chunks):\n",
                "    print(f\"\\nChunk {i+1} ({len(chunk.page_content)} chars):\")\n",
                "    print(chunk.page_content[:100] + \"...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Test Vector Store"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.vectorstore import create_vectorstore, similarity_search\n",
                "\n",
                "# Create vector store from chunks\n",
                "vectorstore = create_vectorstore(chunks)\n",
                "print(\"Vector store created!\")\n",
                "\n",
                "# Test similarity search\n",
                "query = \"What are the benefits of RAG?\"\n",
                "results = similarity_search(vectorstore, query, k=2)\n",
                "\n",
                "print(f\"\\nSearch query: '{query}'\")\n",
                "print(f\"Found {len(results)} results:\")\n",
                "\n",
                "for i, doc in enumerate(results):\n",
                "    print(f\"\\nResult {i+1}:\")\n",
                "    print(doc.page_content[:200])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Test RAG Chain"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.chain import query_rag\n",
                "\n",
                "# Test RAG query\n",
                "question = \"How does the RAG system work? Explain the steps.\"\n",
                "\n",
                "result = query_rag(vectorstore, question, return_sources=True)\n",
                "\n",
                "print(\"Question:\", question)\n",
                "print(\"\\nAnswer:\")\n",
                "print(result[\"answer\"])\n",
                "\n",
                "print(\"\\nSources:\")\n",
                "for source in result.get(\"sources\", []):\n",
                "    print(f\"  - {source['source']} (Page {source['page']})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Cleanup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optional: Clean up test file\n",
                "import os\n",
                "if os.path.exists(test_path):\n",
                "    os.remove(test_path)\n",
                "    print(f\"Removed test file: {test_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ✅ All Systems Ready!\n",
                "\n",
                "If all cells executed successfully, your RAG system is properly configured and ready for use.\n",
                "\n",
                "Next steps:\n",
                "- Run `streamlit run app.py` to launch the web interface\n",
                "- Upload your own documents and start asking questions!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}